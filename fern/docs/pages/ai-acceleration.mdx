---
title: AI & Machine learning acceleration
description: NVIDIA libraries and frameworks for AI and ML workloads.
slug: ai-acceleration
---

NVIDIA provides a rich ecosystem of **GPU-accelerated libraries** for AI, ML, and data science:

## Key Components

- **cuDNN** – GPU-optimized library for deep neural networks  
- **TensorRT** – Optimized inference engine for deploying neural networks efficiently  
- **RAPIDS & cuML** – GPU-accelerated data science and ML tools  
- **Triton Inference Server** – Deploy models at scale for real-time inference  

## Use Cases

- Real-time recommendation engines  
- Autonomous vehicle perception  
- Large-scale language and vision models  
- AI agents in simulation environments  

> These libraries use CUDA under the hood for **maximum performance**, enabling faster training and real-time inference on GPUs.
